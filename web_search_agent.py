#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç½‘ç»œæ£€ç´¢Agent - åŸºäºŽTavily APIçš„æ™ºèƒ½ç½‘ç»œæœç´¢ä¸“å®¶
åŠŸèƒ½ç‰¹æ€§ï¼š
1. å®žæ—¶ç½‘ç»œæœç´¢ - èŽ·å–æœ€æ–°ä¿¡æ¯
2. æ™ºèƒ½å†…å®¹æå– - ä»ŽæŒ‡å®šURLæå–å†…å®¹  
3. å¤šç»´åº¦æœç´¢ - æ”¯æŒæ–°é—»ã€é‡‘èžã€é€šç”¨ç­‰ä¸åŒä¸»é¢˜
4. æœç´¢ç»“æžœä¼˜åŒ– - ä¸“ä¸ºAIå’ŒRAGåº”ç”¨ä¼˜åŒ–
5. çµæ´»å‚æ•°æŽ§åˆ¶ - æœç´¢æ·±åº¦ã€æ—¶é—´èŒƒå›´ã€ç»“æžœæ•°é‡ç­‰
"""

import os
import json
from typing import List, Dict, Any, Optional, Literal
from datetime import datetime, timedelta
from dotenv import load_dotenv 
load_dotenv(override=True)

from langchain_openai import ChatOpenAI
from langchain_tavily import TavilySearch
from langgraph.prebuilt import create_react_agent
from langchain_core.tools import tool
from pydantic import BaseModel, Field
from config.load_key import load_key

# åˆå§‹åŒ–æ¨¡åž‹ - ä½¿ç”¨é˜¿é‡Œäº‘ç™¾ç‚¼ API
model = ChatOpenAI(
    api_key=load_key("aliyun-bailian"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    model="qwen-plus",
)

# èŽ·å–Tavily APIå¯†é’¥
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
TAVILY_AVAILABLE = bool(TAVILY_API_KEY)
if not TAVILY_AVAILABLE:
    import logging
    logging.warning("æœªæ‰¾åˆ°TAVILY_API_KEYçŽ¯å¢ƒå˜é‡ï¼Œweb_search_agentåŠŸèƒ½å°†å—é™")

# =============================================================================
# åŸºç¡€ç½‘ç»œæœç´¢å·¥å…·
# =============================================================================

class WebSearchSchema(BaseModel):
    query: str = Field(description="æœç´¢æŸ¥è¯¢å…³é”®è¯")
    max_results: int = Field(default=5, description="æœ€å¤§æœç´¢ç»“æžœæ•°é‡ï¼ˆ1-20ï¼‰")
    topic: Literal["general", "news", "finance"] = Field(default="general", description="æœç´¢ä¸»é¢˜ç±»åž‹")
    search_depth: Literal["basic", "advanced"] = Field(default="basic", description="æœç´¢æ·±åº¦")
    include_answer: bool = Field(default=True, description="æ˜¯å¦åŒ…å«AIç”Ÿæˆçš„ç­”æ¡ˆæ‘˜è¦")
    include_images: bool = Field(default=False, description="æ˜¯å¦åŒ…å«ç›¸å…³å›¾ç‰‡")
    time_range: Optional[Literal["day", "week", "month", "year"]] = Field(default=None, description="æ—¶é—´èŒƒå›´é™åˆ¶")

@tool(args_schema=WebSearchSchema)
def web_search(
    query: str, 
    max_results: int = 5,
    topic: Literal["general", "news", "finance"] = "general",
    search_depth: Literal["basic", "advanced"] = "basic",
    include_answer: bool = True,
    include_images: bool = False,
    time_range: Optional[Literal["day", "week", "month", "year"]] = None
) -> str:
    """
    æ™ºèƒ½ç½‘ç»œæœç´¢ - èŽ·å–å®žæ—¶ç½‘ç»œä¿¡æ¯
    """
    if not TAVILY_AVAILABLE:
        return "âŒ ç½‘ç»œæœç´¢åŠŸèƒ½ä¸å¯ç”¨ï¼šæœªé…ç½® TAVILY_API_KEYã€‚è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® TAVILY_API_KEYã€‚"
    
    try:
        # åˆ›å»ºTavilyæœç´¢å·¥å…·
        tavily_search = TavilySearch(
            api_key=TAVILY_API_KEY,
            max_results=max_results,
            topic=topic,
            include_answer=include_answer,
            search_depth=search_depth
        )
        
        # æž„å»ºæœç´¢å‚æ•°
        search_params = {"query": query}
        if include_images:
            search_params["include_images"] = include_images
        if time_range:
            search_params["time_range"] = time_range
        if search_depth != "basic":
            search_params["search_depth"] = search_depth
        
        # æ‰§è¡Œæœç´¢
        results = tavily_search.invoke(search_params)
        
        # è§£æžç»“æžœ
        if isinstance(results, str):
            # å¦‚æžœè¿”å›žå­—ç¬¦ä¸²ï¼Œå°è¯•è§£æžä¸ºJSON
            try:
                results = json.loads(results)
            except:
                return f"âœ… æœç´¢å®Œæˆ\n\nðŸ“‹ æœç´¢ç»“æžœ:\n{results}"
        
        # æ ¼å¼åŒ–è¾“å‡º
        response = f"ðŸ” ç½‘ç»œæœç´¢å®Œæˆ - æŸ¥è¯¢: \"{query}\"\n"
        response += f"ðŸ“Š æœç´¢å‚æ•°: ä¸»é¢˜={topic}, æ·±åº¦={search_depth}, ç»“æžœæ•°={max_results}\n\n"
        
        if isinstance(results, list):
            # å¤„ç†æœç´¢ç»“æžœåˆ—è¡¨
            for i, result in enumerate(results[:max_results], 1):
                if isinstance(result, dict):
                    title = result.get('title', 'æ— æ ‡é¢˜')
                    url = result.get('url', '')
                    content = result.get('content', result.get('snippet', ''))
                    
                    response += f"ðŸ“„ ç»“æžœ {i}: {title}\n"
                    response += f"ðŸ”— é“¾æŽ¥: {url}\n"
                    response += f"ðŸ“ æ‘˜è¦: {content[:200]}...\n\n"
                else:
                    response += f"ðŸ“„ ç»“æžœ {i}: {result}\n\n"
        elif isinstance(results, dict):
            # å¤„ç†å•ä¸ªç»“æžœå­—å…¸
            if "answer" in results:
                response += f"ðŸ¤– AIç­”æ¡ˆæ‘˜è¦:\n{results['answer']}\n\n"
            
            if "results" in results:
                search_results = results["results"]
                for i, result in enumerate(search_results[:max_results], 1):
                    title = result.get('title', 'æ— æ ‡é¢˜')
                    url = result.get('url', '')
                    content = result.get('content', result.get('snippet', ''))
                    
                    response += f"ðŸ“„ ç»“æžœ {i}: {title}\n"
                    response += f"ðŸ”— é“¾æŽ¥: {url}\n"
                    response += f"ðŸ“ æ‘˜è¦: {content[:200]}...\n\n"
        else:
            response += f"ðŸ“‹ æœç´¢ç»“æžœ:\n{str(results)}"
        
        return response
        
    except Exception as e:
        return f"âŒ ç½‘ç»œæœç´¢å¤±è´¥: {str(e)}"

# =============================================================================
# æ–°é—»æœç´¢å·¥å…·
# =============================================================================

class NewsSearchSchema(BaseModel):
    query: str = Field(description="æ–°é—»æœç´¢å…³é”®è¯")
    max_results: int = Field(default=5, description="æœ€å¤§æ–°é—»ç»“æžœæ•°é‡")
    time_range: Literal["day", "week", "month"] = Field(default="week", description="æ–°é—»æ—¶é—´èŒƒå›´")

@tool(args_schema=NewsSearchSchema)
def news_search(query: str, max_results: int = 5, time_range: Literal["day", "week", "month"] = "week") -> str:
    """
    ä¸“é—¨çš„æ–°é—»æœç´¢ - èŽ·å–æœ€æ–°æ–°é—»èµ„è®¯
    """
    if not TAVILY_AVAILABLE:
        return "âŒ æ–°é—»æœç´¢åŠŸèƒ½ä¸å¯ç”¨ï¼šæœªé…ç½® TAVILY_API_KEYã€‚"
    
    try:
        tavily_search = TavilySearch(
            api_key=TAVILY_API_KEY,
            max_results=max_results,
            topic="news",
            include_answer=True,
            search_depth="advanced"
        )
        
        results = tavily_search.invoke({
            "query": query,
            "time_range": time_range
        })
        
        response = f"ðŸ“° æ–°é—»æœç´¢å®Œæˆ - æŸ¥è¯¢: \"{query}\"\n"
        response += f"â° æ—¶é—´èŒƒå›´: æœ€è¿‘{time_range}\n\n"
        
        if isinstance(results, str):
            try:
                results = json.loads(results)
            except:
                return response + results
        
        if isinstance(results, dict) and "results" in results:
            if "answer" in results:
                response += f"ðŸ“ æ–°é—»æ‘˜è¦:\n{results['answer']}\n\n"
            
            news_results = results["results"]
            for i, news in enumerate(news_results[:max_results], 1):
                title = news.get('title', 'æ— æ ‡é¢˜')
                url = news.get('url', '')
                content = news.get('content', news.get('snippet', ''))
                published_date = news.get('published_date', 'æœªçŸ¥æ—¶é—´')
                
                response += f"ðŸ“° æ–°é—» {i}: {title}\n"
                response += f"ðŸ“… å‘å¸ƒæ—¶é—´: {published_date}\n"
                response += f"ðŸ”— é“¾æŽ¥: {url}\n"
                response += f"ðŸ“ å†…å®¹: {content[:250]}...\n\n"
        
        return response
        
    except Exception as e:
        return f"âŒ æ–°é—»æœç´¢å¤±è´¥: {str(e)}"

# =============================================================================
# URLå†…å®¹æå–å·¥å…·
# =============================================================================

class URLExtractSchema(BaseModel):
    urls: List[str] = Field(description="è¦æå–å†…å®¹çš„URLåˆ—è¡¨")
    max_content_length: int = Field(default=2000, description="æ¯ä¸ªURLæå–å†…å®¹çš„æœ€å¤§é•¿åº¦")

@tool(args_schema=URLExtractSchema)
def extract_url_content(urls: List[str], max_content_length: int = 2000) -> str:
    """
    ä»ŽæŒ‡å®šURLæå–å†…å®¹ - æ™ºèƒ½ç½‘é¡µå†…å®¹æŠ“å–
    """
    if not TAVILY_AVAILABLE:
        return "âŒ URLå†…å®¹æå–åŠŸèƒ½ä¸å¯ç”¨ï¼šæœªé…ç½® TAVILY_API_KEYã€‚"
    
    try:
        if not urls:
            return "âŒ URLåˆ—è¡¨ä¸èƒ½ä¸ºç©º"
        
        # æ³¨æ„ï¼šTavilyçš„ExtractåŠŸèƒ½éœ€è¦ä¸“é—¨çš„å·¥å…·
        from langchain_tavily import TavilyExtract
        
        tavily_extract = TavilyExtract(api_key=TAVILY_API_KEY)
        
        results = tavily_extract.invoke({"urls": urls})
        
        response = f"ðŸ“„ URLå†…å®¹æå–å®Œæˆ - å¤„ç† {len(urls)} ä¸ªé“¾æŽ¥\n\n"
        
        if isinstance(results, list):
            for i, result in enumerate(results, 1):
                if isinstance(result, dict):
                    url = result.get('url', f'URL {i}')
                    title = result.get('title', 'æ— æ ‡é¢˜')
                    content = result.get('content', 'æ— å†…å®¹')
                    
                    # é™åˆ¶å†…å®¹é•¿åº¦
                    if len(content) > max_content_length:
                        content = content[:max_content_length] + "...(å†…å®¹å·²æˆªæ–­)"
                    
                    response += f"ðŸ”— é“¾æŽ¥ {i}: {url}\n"
                    response += f"ðŸ“‹ æ ‡é¢˜: {title}\n"
                    response += f"ðŸ“ å†…å®¹:\n{content}\n\n"
                    response += "-" * 50 + "\n\n"
        else:
            response += f"ðŸ“„ æå–ç»“æžœ:\n{str(results)}"
        
        return response
        
    except ImportError:
        # å¦‚æžœæ²¡æœ‰TavilyExtractï¼Œä½¿ç”¨åŸºç¡€æœç´¢æ–¹å¼
        return "âš ï¸ URLå†…å®¹æå–åŠŸèƒ½éœ€è¦æ›´æ–°langchain-tavilyåŒ…ç‰ˆæœ¬"
    except Exception as e:
        return f"âŒ URLå†…å®¹æå–å¤±è´¥: {str(e)}"

# =============================================================================
# é‡‘èžä¿¡æ¯æœç´¢å·¥å…·
# =============================================================================

class FinanceSearchSchema(BaseModel):
    query: str = Field(description="é‡‘èžç›¸å…³æœç´¢å…³é”®è¯")
    max_results: int = Field(default=5, description="æœ€å¤§æœç´¢ç»“æžœæ•°é‡")

@tool(args_schema=FinanceSearchSchema)
def finance_search(query: str, max_results: int = 5) -> str:
    """
    é‡‘èžä¿¡æ¯æœç´¢ - èŽ·å–è‚¡ç¥¨ã€å¸‚åœºã€ç»æµŽç›¸å…³ä¿¡æ¯
    """
    if not TAVILY_AVAILABLE:
        return "âŒ é‡‘èžæœç´¢åŠŸèƒ½ä¸å¯ç”¨ï¼šæœªé…ç½® TAVILY_API_KEYã€‚"
    
    try:
        tavily_search = TavilySearch(
            api_key=TAVILY_API_KEY,
            max_results=max_results,
            topic="finance",
            include_answer=True,
            search_depth="advanced"
        )
        
        results = tavily_search.invoke({"query": query})
        
        response = f"ðŸ’° é‡‘èžä¿¡æ¯æœç´¢å®Œæˆ - æŸ¥è¯¢: \"{query}\"\n\n"
        
        if isinstance(results, str):
            try:
                results = json.loads(results)
            except:
                return response + results
        
        if isinstance(results, dict) and "results" in results:
            if "answer" in results:
                response += f"ðŸ“Š é‡‘èžåˆ†æž:\n{results['answer']}\n\n"
            
            finance_results = results["results"]
            for i, result in enumerate(finance_results[:max_results], 1):
                title = result.get('title', 'æ— æ ‡é¢˜')
                url = result.get('url', '')
                content = result.get('content', result.get('snippet', ''))
                
                response += f"ðŸ’¹ ä¿¡æ¯ {i}: {title}\n"
                response += f"ðŸ”— æ¥æº: {url}\n"
                response += f"ðŸ“ è¯¦æƒ…: {content[:200]}...\n\n"
        
        return response
        
    except Exception as e:
        return f"âŒ é‡‘èžä¿¡æ¯æœç´¢å¤±è´¥: {str(e)}"

# =============================================================================
# æ™ºèƒ½æœç´¢å»ºè®®å·¥å…·
# =============================================================================

@tool
def get_search_suggestions(topic: str) -> str:
    """
    èŽ·å–æœç´¢å»ºè®®å’Œæœ€ä½³å®žè·µ
    """
    suggestions = {
        "æ–°é—»": [
            "æ·»åŠ å…·ä½“æ—¶é—´å…³é”®è¯ï¼Œå¦‚'2024å¹´æœ€æ–°'",
            "åŒ…å«åœ°ç†ä½ç½®ï¼Œå¦‚'ä¸­å›½'ã€'å…¨çƒ'",
            "ä½¿ç”¨æ–°é—»ç›¸å…³è¯æ±‡ï¼Œå¦‚'æŠ¥é“'ã€'æ¶ˆæ¯'ã€'äº‹ä»¶'"
        ],
        "æŠ€æœ¯": [
            "åŒ…å«ç‰ˆæœ¬ä¿¡æ¯ï¼Œå¦‚'Python 3.12'",
            "æ·»åŠ 'æ•™ç¨‹'ã€'æ–‡æ¡£'ã€'æœ€ä½³å®žè·µ'ç­‰å…³é”®è¯",
            "æŒ‡å®šå…·ä½“æŠ€æœ¯æ ˆï¼Œå¦‚'React + TypeScript'"
        ],
        "é‡‘èž": [
            "åŒ…å«å…·ä½“è‚¡ç¥¨ä»£ç æˆ–å…¬å¸åç§°",
            "æ·»åŠ æ—¶é—´èŒƒå›´ï¼Œå¦‚'Q3 2024'",
            "ä½¿ç”¨é‡‘èžä¸“ä¸šæœ¯è¯­ï¼Œå¦‚'å¸‚å€¼'ã€'PEæ¯”çŽ‡'"
        ],
        "å­¦æœ¯": [
            "æ·»åŠ 'è®ºæ–‡'ã€'ç ”ç©¶'ã€'å­¦æœ¯'ç­‰å…³é”®è¯",
            "åŒ…å«å…·ä½“é¢†åŸŸï¼Œå¦‚'æœºå™¨å­¦ä¹ 'ã€'ç”Ÿç‰©åŒ»å­¦'",
            "æŒ‡å®šå‘è¡¨å¹´ä»½æˆ–æœŸåˆŠåç§°"
        ]
    }
    
    response = f"ðŸŽ¯ æœç´¢å»ºè®® - ä¸»é¢˜: {topic}\n\n"
    
    if topic in suggestions:
        response += f"ðŸ’¡ é’ˆå¯¹'{topic}'çš„æœç´¢ä¼˜åŒ–å»ºè®®:\n"
        for suggestion in suggestions[topic]:
            response += f"â€¢ {suggestion}\n"
    else:
        response += "ðŸ’¡ é€šç”¨æœç´¢ä¼˜åŒ–å»ºè®®:\n"
        response += "â€¢ ä½¿ç”¨å…·ä½“è€Œéžæ³›æ³›çš„å…³é”®è¯\n"
        response += "â€¢ åŒ…å«æ—¶é—´é™å®šè¯\n"
        response += "â€¢ æ·»åŠ åœ°ç†ä½ç½®ä¿¡æ¯\n"
        response += "â€¢ ä½¿ç”¨ä¸“ä¸šæœ¯è¯­æé«˜å‡†ç¡®æ€§\n"
    
    response += "\nðŸ”§ å¯ç”¨æœç´¢å·¥å…·:\n"
    response += "â€¢ web_search - é€šç”¨ç½‘ç»œæœç´¢\n"
    response += "â€¢ news_search - æ–°é—»èµ„è®¯æœç´¢\n"
    response += "â€¢ finance_search - é‡‘èžä¿¡æ¯æœç´¢\n"
    response += "â€¢ extract_url_content - URLå†…å®¹æå–\n"
    
    return response

# =============================================================================
# Agenté…ç½®
# =============================================================================

# ç³»ç»Ÿæç¤ºè¯
WEB_SEARCH_AGENT_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç½‘ç»œä¿¡æ¯æ£€ç´¢ä¸“å®¶ï¼ŒåŸºäºŽTavily APIæä¾›å¼ºå¤§çš„å®žæ—¶ç½‘ç»œæœç´¢èƒ½åŠ›ï¼Œç¦æ­¢åŽ»æˆäººç½‘ç«™æ£€ç´¢ã€‚ä½ å…·å¤‡ä»¥ä¸‹æ ¸å¿ƒèƒ½åŠ›ï¼š
ðŸ” **ä¸ªäººä¿¡æ¯æ£€ç´¢**:
- å®žæ—¶èŽ·å–æœ€æ–°ç½‘ç»œä¿¡æ¯(å…¬ä¼—å·ï¼Œç½‘é¡µç­‰æ¥æº)
ðŸ” **æ™ºèƒ½ç½‘ç»œæœç´¢**:
- å®žæ—¶èŽ·å–æœ€æ–°ç½‘ç»œä¿¡æ¯
- æ”¯æŒé€šç”¨ã€æ–°é—»ã€é‡‘èžç­‰ä¸åŒä¸»é¢˜æœç´¢
- çµæ´»çš„æœç´¢æ·±åº¦å’Œç»“æžœæ•°é‡æŽ§åˆ¶
- AIä¼˜åŒ–çš„æœç´¢ç»“æžœï¼Œä¸“ä¸ºçŸ¥è¯†é—®ç­”è®¾è®¡

ðŸ“° **ä¸“ä¸šæ–°é—»æœç´¢**:
- èŽ·å–æœ€æ–°æ–°é—»èµ„è®¯
- æ”¯æŒæ—¶é—´èŒƒå›´ç­›é€‰ï¼ˆæœ€è¿‘ä¸€å¤©/å‘¨/æœˆï¼‰
- æä¾›æ–°é—»æ‘˜è¦å’Œå‘å¸ƒæ—¶é—´
- æ·±åº¦æœç´¢æ¨¡å¼èŽ·å–è¯¦ç»†ä¿¡æ¯

ðŸ’° **é‡‘èžä¿¡æ¯æœç´¢**:
- ä¸“é—¨çš„é‡‘èžå’Œå¸‚åœºä¿¡æ¯æ£€ç´¢
- èŽ·å–è‚¡ç¥¨ã€ç»æµŽã€å¸‚åœºåŠ¨æ€
- æä¾›ä¸“ä¸šçš„é‡‘èžåˆ†æžå’Œè§è§£

ðŸ“„ **æ™ºèƒ½å†…å®¹æå–**:
- ä»ŽæŒ‡å®šURLæå–å’Œåˆ†æžå†…å®¹
- æ”¯æŒæ‰¹é‡URLå¤„ç†
- æ™ºèƒ½å†…å®¹æ‘˜è¦å’Œç»“æž„åŒ–è¾“å‡º

**å¯ç”¨å·¥å…·**:
1. **`web_search`** - é€šç”¨ç½‘ç»œæœç´¢ï¼ˆä¸»è¦å·¥å…·ï¼‰
2. **`news_search`** - ä¸“ä¸šæ–°é—»æœç´¢
3. **`finance_search`** - é‡‘èžä¿¡æ¯æœç´¢
4. **`extract_url_content`** - URLå†…å®¹æå–
5. **`get_search_suggestions`** - æœç´¢å»ºè®®å’Œä¼˜åŒ–

**æœç´¢ç‰¹è‰²**:
- âœ… å®žæ—¶ä¿¡æ¯ï¼Œæ¯”ä¼ ç»Ÿæœç´¢å¼•æ“Žæ›´æ–°æ›´å¿«
- âœ… AIä¼˜åŒ–ç»“æžœï¼Œç›´æŽ¥æä¾›ç­”æ¡ˆæ‘˜è¦
- âœ… å¤šç»´åº¦æœç´¢ï¼Œæ”¯æŒä¸åŒä¸»é¢˜å’Œæ·±åº¦
- âœ… ç»“æž„åŒ–è¾“å‡ºï¼Œä¾¿äºŽåŽç»­å¤„ç†

**ä½¿ç”¨åŽŸåˆ™**:
- æ ¹æ®ç”¨æˆ·æŸ¥è¯¢ç±»åž‹é€‰æ‹©æœ€åˆé€‚çš„æœç´¢å·¥å…·
- ä¼˜å…ˆä½¿ç”¨ `web_search` è¿›è¡Œé€šç”¨æœç´¢
- æ–°é—»ç›¸å…³æŸ¥è¯¢ä½¿ç”¨ `news_search`
- é‡‘èžç›¸å…³æŸ¥è¯¢ä½¿ç”¨ `finance_search`
- éœ€è¦å…·ä½“ç½‘é¡µå†…å®¹æ—¶ä½¿ç”¨ `extract_url_content`
- æä¾›æ¸…æ™°ã€ç»“æž„åŒ–çš„æœç´¢ç»“æžœ
- åœ¨é€‚å½“æ—¶å€™æä¾›æœç´¢ä¼˜åŒ–å»ºè®®

è¯·æ ¹æ®ç”¨æˆ·çš„æŸ¥è¯¢éœ€æ±‚ï¼Œé€‰æ‹©æœ€åˆé€‚çš„å·¥å…·æ¥èŽ·å–å‡†ç¡®ã€åŠæ—¶çš„ç½‘ç»œä¿¡æ¯ï¼
"""

# åˆ›å»ºAgent
web_search_agent = create_react_agent(
    model=model,
    tools=[
        web_search,
        news_search,
        finance_search,
        extract_url_content,
        get_search_suggestions
    ],
    name="web_search_agent"
)

if __name__ == "__main__":
    print("ðŸš€ ç½‘ç»œæ£€ç´¢Agentå·²å¯åŠ¨ï¼")
    print("åŠŸèƒ½åŒ…æ‹¬ï¼š")
    print("- ðŸ” å®žæ—¶ç½‘ç»œæœç´¢ï¼ˆé€šç”¨ã€æ–°é—»ã€é‡‘èžï¼‰")
    print("- ðŸ“„ æ™ºèƒ½URLå†…å®¹æå–")
    print("- ðŸŽ¯ æœç´¢å»ºè®®å’Œä¼˜åŒ–")
    print("- ðŸ¤– AIä¼˜åŒ–çš„æœç´¢ç»“æžœ")
    print("- âš¡ å¿«é€Ÿå“åº”ï¼Œä¸“ä¸ºAIåº”ç”¨è®¾è®¡")
    
    # æµ‹è¯•æœç´¢åŠŸèƒ½
    print("\nðŸ§ª æµ‹è¯•ç½‘ç»œæœç´¢åŠŸèƒ½...")
    try:
        test_result = web_search.invoke({
            "query": "Python 3.12 æ–°ç‰¹æ€§", 
            "max_results": 3
        })
        print("æµ‹è¯•ç»“æžœï¼š", test_result[:300] + "..." if len(test_result) > 300 else test_result)
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {e}")