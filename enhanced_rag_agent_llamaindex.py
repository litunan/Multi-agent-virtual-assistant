"""
å¢å¼ºç‰ˆ RAG Agent - LlamaIndex å®ç°
ä½¿ç”¨ LlamaIndex FAISS å‘é‡æ•°æ®åº“è¿›è¡ŒçŸ¥è¯†æ£€ç´¢
ä½œè€…: AI Assistant
æ—¥æœŸ: 2025-12-22
"""
from __future__ import annotations
import os
import json
import asyncio
from typing import Literal, List, Dict, Any, Optional
from dotenv import load_dotenv

load_dotenv(override=True)

from langchain_deepseek import ChatDeepSeek
from langgraph.graph import MessagesState, StateGraph, START, END
from pydantic import BaseModel, Field
from langchain_core.tools import BaseTool
from langchain_core.callbacks import CallbackManagerForToolRun
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, SystemMessage
import re
from datetime import datetime
from collections import defaultdict
import math
from langchain_openai import ChatOpenAI

# LlamaIndex imports
from llama_index.core import StorageContext, load_index_from_storage, Settings
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.vector_stores.faiss import FaissVectorStore
from config.load_key import load_key

# åˆå§‹åŒ–æ¨¡å‹
model = ChatOpenAI(
    # è‹¥æ²¡æœ‰é…ç½®ç¯å¢ƒå˜é‡,è¯·ç”¨ç™¾ç‚¼API Keyå°†ä¸‹è¡Œæ›¿æ¢ä¸ºï¼šapi_key="sk-xxx"
    api_key=load_key("aliyun-bailian"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    model="qwen-plus",  # é˜¿é‡Œäº‘ç™¾ç‚¼æ¨¡å‹
)



grader_model = ChatOpenAI(
    # è‹¥æ²¡æœ‰é…ç½®ç¯å¢ƒå˜é‡,è¯·ç”¨ç™¾ç‚¼API Keyå°†ä¸‹è¡Œæ›¿æ¢ä¸ºï¼šapi_key="sk-xxx"
    api_key=load_key("aliyun-bailian"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    model="qwen-plus",  # é˜¿é‡Œäº‘ç™¾ç‚¼æ¨¡å‹
)




class EnhancedTextRetrieverLlamaIndex(BaseTool):
    """å¢å¼ºç‰ˆ LlamaIndex å‘é‡æ•°æ®åº“æ£€ç´¢å·¥å…· - æŠ—ç™Œè‚½ä¸“ç”¨"""
    name: str = "retrieve_anticancer_peptides"
    description: str = "Search and return relevant information from the Anticancer Peptides knowledge base using LlamaIndex FAISS vector database."
    conversation_history: List[str] = []
    context_cache: Dict[str, Any] = {}
    index: Any = None
    retriever: Any = None

    def __init__(self):
        """åˆå§‹åŒ–æ£€ç´¢å·¥å…·"""
        super().__init__()
        self.conversation_history = []
        self.context_cache = {}
        self._initialize_vectorstore()

    def _initialize_vectorstore(self):
        """åˆå§‹åŒ– LlamaIndex FAISS å‘é‡æ•°æ®åº“"""
        try:
            # åˆå§‹åŒ– embeddings - ä½¿ç”¨æœ¬åœ° HuggingFace æ¨¡å‹
            embed_model = HuggingFaceEmbedding(
                model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
                device="cpu",
                normalize=True,
            )
            Settings.embed_model = embed_model

            # åŠ è½½ LlamaIndex FAISS å‘é‡æ•°æ®åº“
            output_dir = "mcp_course_materials_db_llamaindex"
            vector_store = FaissVectorStore.from_persist_dir(output_dir)
            storage_context = StorageContext.from_defaults(
                vector_store=vector_store,
                persist_dir=output_dir,
            )
            
            self.index = load_index_from_storage(storage_context, embed_model=embed_model)
            self.retriever = self.index.as_retriever(similarity_top_k=5)
            print("LlamaIndex å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"åŠ è½½å‘é‡æ•°æ®åº“å¤±è´¥: {str(e)}")
            self.index = None
            self.retriever = None

    def _run(self, query: str, run_manager: CallbackManagerForToolRun = None) -> str:
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£å†…å®¹"""
        try:
            # ä¿å­˜å¯¹è¯å†å²
            self.conversation_history.append(query)

            if self.retriever is None:
                return "å‘é‡æ•°æ®åº“æœªåˆå§‹åŒ–,è¯·æ£€æŸ¥é…ç½®ã€‚"

            # å¢å¼ºæŸ¥è¯¢å¤„ç†
            enhanced_query = self._enhance_query(query)

            # æ‰§è¡Œå‘é‡æœç´¢
            results = self._vector_search(enhanced_query, top_k=5)

            if not results:
                # å°è¯•æ‰©å±•æœç´¢
                expanded_results = self._expanded_search(query)
                if expanded_results:
                    return self._format_expanded_results(expanded_results, query)
                return f"æœªæ‰¾åˆ°ä¸'{query}'ç›´æ¥ç›¸å…³çš„ä¿¡æ¯ã€‚æ‚¨å¯ä»¥å°è¯•ä½¿ç”¨æ›´å…·ä½“çš„å…³é”®è¯ï¼Œæˆ–è¯¢é—®ä»¥ä¸‹ç›¸å…³é—®é¢˜ï¼š\n" + self._suggest_questions()

            # æ ¼å¼åŒ–ç»“æœ
            formatted_result = self._format_enhanced_results(results, query)

            # ç¼“å­˜ä¸Šä¸‹æ–‡
            self.context_cache[query] = results

            return formatted_result

        except Exception as e:
            return f"æ£€ç´¢æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"

    def _enhance_query(self, query: str) -> Dict[str, Any]:
        """å¢å¼ºæŸ¥è¯¢å¤„ç†"""
        enhanced = {
            'original': query,
            'terms': self._extract_key_terms(query),
            'intent': self._analyze_intent(query),
            'context': self._get_conversation_context(),
            'synonyms': self._get_synonyms(query)
        }
        return enhanced

    def _extract_key_terms(self, query: str) -> List[str]:
        """æå–å…³é”®æœ¯è¯­ - æŠ—ç™Œè‚½é¢†åŸŸ"""
        technical_terms = {
            'æŠ—ç™Œè‚½': ['anticancer peptides', 'ACPs', 'æŠ—è‚¿ç˜¤è‚½', 'æŠ—ç™Œå¤šè‚½'],
            'è‚½': ['peptide', 'å¤šè‚½', 'çŸ­è‚½', 'è›‹ç™½è´¨ç‰‡æ®µ'],
            'ç™Œç—‡': ['cancer', 'è‚¿ç˜¤', 'æ¶æ€§è‚¿ç˜¤', 'ç™Œå˜'],
            'ç»†èƒ': ['cell', 'ç»†èƒç³»', 'ç™Œç»†èƒ', 'è‚¿ç˜¤ç»†èƒ'],
            'æœºåˆ¶': ['mechanism', 'ä½œç”¨æœºåˆ¶', 'æœºç†', 'åˆ†å­æœºåˆ¶'],
            'æ¯’æ€§': ['toxicity', 'ç»†èƒæ¯’æ€§', 'æ¯’å‰¯ä½œç”¨', 'å®‰å…¨æ€§'],
            'é€‰æ‹©æ€§': ['selectivity', 'ç‰¹å¼‚æ€§', 'é¶å‘æ€§', 'é€‰æ‹©æ€§æ€ä¼¤'],
            'ç»“æ„': ['structure', 'æ„æ•ˆå…³ç³»', 'äºŒçº§ç»“æ„', 'ç©ºé—´ç»“æ„'],
            'æ´»æ€§': ['activity', 'ç”Ÿç‰©æ´»æ€§', 'æŠ—ç™Œæ´»æ€§', 'æŠ‘åˆ¶æ´»æ€§'],
            'æ²»ç–—': ['therapy', 'æ²»ç–—', 'è¯ç‰©æ²»ç–—', 'é¶å‘æ²»ç–—'],
            'é¢„æµ‹': ['prediction', 'è¯†åˆ«', 'åˆ†ç±»', 'æœºå™¨å­¦ä¹ '],
            'æ•°æ®åº“': ['database', 'æ•°æ®é›†', 'èµ„æºåº“', 'ä¿¡æ¯åº“'],
            'è®¾è®¡': ['design', 'ç†æ€§è®¾è®¡', 'ä¼˜åŒ–è®¾è®¡', 'è‚½è®¾è®¡'],
            'ç©¿é€': ['penetration', 'ç»†èƒç©¿é€', 'è†œç©¿é€', 'ç»†èƒå†…åŒ–'],
            'è€è¯æ€§': ['resistance', 'è€è¯', 'è¯ç‰©æŠµæŠ—', 'æ²»ç–—æŠµæŠ—'],
            'ç”Ÿç‰©ä¿¡æ¯å­¦': ['bioinformatics', 'è®¡ç®—ç”Ÿç‰©å­¦', 'ç”Ÿç‰©è®¡ç®—'],
            'åˆ†å­å¯¹æ¥': ['docking', 'åˆ†å­æ¨¡æ‹Ÿ', 'è®¡ç®—æœºè¾…åŠ©è®¾è®¡'],
            'ä¸´åºŠè¯•éªŒ': ['clinical trial', 'ä¸´åºŠç ”ç©¶', 'äººä½“è¯•éªŒ']
        }

        terms = []
        query_lower = query.lower()

        for key, synonyms in technical_terms.items():
            if key in query or any(syn in query_lower for syn in synonyms):
                terms.extend([key] + synonyms)

        # æ·»åŠ åŸå§‹æŸ¥è¯¢è¯
        terms.extend(query.split())

        return list(set(terms))

    def _analyze_intent(self, query: str) -> str:
        """åˆ†ææŸ¥è¯¢æ„å›¾"""
        intent_patterns = {
            'definition': ['æ˜¯ä»€ä¹ˆ', 'å®šä¹‰', 'å«ä¹‰', 'è§£é‡Š', 'æ¦‚å¿µ'],
            'method': ['å¦‚ä½•', 'æ€ä¹ˆ', 'æ–¹æ³•', 'æ­¥éª¤', 'æµç¨‹'],
            'comparison': ['æ¯”è¾ƒ', 'åŒºåˆ«', 'å·®å¼‚', 'å¯¹æ¯”', 'å¼‚åŒ'],
            'analysis': ['åˆ†æ', 'è¯„ä¼°', 'ç ”ç©¶', 'æ¢è®¨', 'è°ƒæŸ¥'],
            'example': ['ä¾‹å­', 'ç¤ºä¾‹', 'æ¡ˆä¾‹', 'ä¸¾ä¾‹', 'å®ä¾‹'],
            'reason': ['ä¸ºä»€ä¹ˆ', 'åŸå› ', 'å› ç´ ', 'å½±å“', 'å¯¼è‡´'],
            'process': ['è¿‡ç¨‹', 'æµç¨‹', 'æ­¥éª¤', 'é˜¶æ®µ', 'ç¯èŠ‚'],
            'mechanism': ['æœºåˆ¶', 'åŸç†', 'ä½œç”¨æ–¹å¼', 'åˆ†å­æœºåˆ¶']
        }

        query_lower = query.lower()
        for intent, patterns in intent_patterns.items():
            if any(pattern in query_lower for pattern in patterns):
                return intent
        return 'general'

    def _get_conversation_context(self) -> List[str]:
        """è·å–å¯¹è¯ä¸Šä¸‹æ–‡"""
        return self.conversation_history[-3:] if len(self.conversation_history) > 1 else []

    def _get_synonyms(self, query: str) -> List[str]:
        """è·å–åŒä¹‰è¯"""
        synonym_dict = {
            'æŠ—ç™Œè‚½': ['æŠ—è‚¿ç˜¤è‚½', 'æŠ—ç™Œå¤šè‚½', 'ACPs'],
            'è‚½': ['å¤šè‚½', 'è›‹ç™½è´¨ç‰‡æ®µ', 'çŸ­è‚½'],
            'ç™Œç—‡': ['è‚¿ç˜¤', 'æ¶æ€§è‚¿ç˜¤', 'ç™Œ'],
            'æœºåˆ¶': ['æœºç†', 'ä½œç”¨æœºåˆ¶', 'åˆ†å­æœºåˆ¶'],
            'æ¯’æ€§': ['ç»†èƒæ¯’æ€§', 'æ¯’å‰¯ä½œç”¨'],
            'é€‰æ‹©æ€§': ['ç‰¹å¼‚æ€§', 'é¶å‘æ€§'],
            'æ´»æ€§': ['ç”Ÿç‰©æ´»æ€§', 'æŠ‘åˆ¶æ´»æ€§'],
            'é¢„æµ‹': ['è¯†åˆ«', 'åˆ†ç±»', 'é‰´å®š']
        }

        synonyms = []
        for word, syns in synonym_dict.items():
            if word in query:
                synonyms.extend(syns)

        return synonyms

    def _vector_search(self, enhanced_query: Dict, top_k: int = 5) -> List[Dict]:
        """ä½¿ç”¨ LlamaIndex FAISS è¿›è¡Œå‘é‡æœç´¢"""
        if self.retriever is None:
            return []

        try:
            # ä½¿ç”¨å¢å¼ºçš„æŸ¥è¯¢è¿›è¡Œæœç´¢
            search_query = enhanced_query['original']

            # è·å–å…³é”®æœ¯è¯­å’ŒåŒä¹‰è¯ï¼Œç»„åˆæˆä¸€ä¸ªå¢å¼ºæŸ¥è¯¢
            enhanced_terms = ' '.join(enhanced_query['terms'])
            synonyms = ' '.join(enhanced_query['synonyms'])

            # è·å–æ„å›¾
            query_intent = enhanced_query['intent']

            # åŸºäºæ„å›¾åˆ†æè°ƒæ•´æŸ¥è¯¢ç­–ç•¥
            if query_intent == 'definition':
                full_query = search_query
            elif query_intent == 'comparison':
                full_query = f"{search_query} {enhanced_terms} {synonyms}"
            elif query_intent == 'analysis':
                full_query = f"{search_query} {enhanced_terms} {synonyms}"
            else:
                full_query = f"{search_query} {enhanced_terms} {synonyms}"
            
            # æ‰§è¡Œ LlamaIndex æ£€ç´¢
            nodes = self.retriever.retrieve(full_query)

            results = []
            for i, node in enumerate(nodes[:top_k]):
                # è·å–èŠ‚ç‚¹åˆ†æ•°
                relevance_score = float(node.score) if hasattr(node, 'score') else (1.0 - i * 0.1)

                results.append({
                    'content': node.get_content(),
                    'metadata': node.metadata,
                    'relevance': min(relevance_score, 1.0),
                    'score': relevance_score,
                    'title': node.metadata.get('file_name', 'æœªçŸ¥æ¥æº'),
                    'chunk_id': i
                })

            return results

        except Exception as e:
            print(f"å‘é‡æœç´¢é”™è¯¯: {str(e)}")
            return []

    def _expanded_search(self, query: str) -> List[Dict]:
        """æ‰©å±•æœç´¢ç­–ç•¥"""
        if self.retriever is None:
            return []

        try:
            # å°è¯•ä½¿ç”¨å…³é”®æœ¯è¯­è¿›è¡Œæœç´¢
            enhanced_query = self._enhance_query(query)
            terms = enhanced_query['terms']

            expanded_results = []
            for term in terms[:3]:  # åªä½¿ç”¨å‰3ä¸ªå…³é”®æœ¯è¯­
                nodes = self.retriever.retrieve(term)
                for node in nodes[:2]:
                    expanded_results.append({
                        'content': node.get_content(),
                        'metadata': node.metadata,
                        'relevance': 0.5,
                        'score': 0.5,
                        'title': node.metadata.get('file_name', 'æœªçŸ¥æ¥æº'),
                        'search_term': term
                    })

            # å»é‡
            unique_results = []
            seen_content = set()
            for result in expanded_results:
                content_hash = hash(result['content'][:100])
                if content_hash not in seen_content:
                    seen_content.add(content_hash)
                    unique_results.append(result)

            return unique_results[:3]

        except Exception as e:
            print(f"æ‰©å±•æœç´¢é”™è¯¯: {str(e)}")
            return []

    def _format_enhanced_results(self, results: List[Dict], query: str) -> str:
        """æ ¼å¼åŒ–å¢å¼ºæœç´¢ç»“æœ"""
        if not results:
            return "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"

        formatted_results = []
        formatted_results.append(f"é’ˆå¯¹æŸ¥è¯¢ã€Œ{query}ã€æ‰¾åˆ°ä»¥ä¸‹ç›¸å…³ä¿¡æ¯ï¼š\n")

        for i, result in enumerate(results, 1):
            relevance_score = result.get('relevance', 0)
            confidence = "é«˜" if relevance_score > 0.7 else "ä¸­" if relevance_score > 0.4 else "ä½"

            formatted_results.append(f"ğŸ“Œ ã€ç›¸å…³å†…å®¹ {i}ã€‘ï¼ˆç›¸å…³åº¦ï¼š{confidence}ï¼‰")

            # æ˜¾ç¤ºæ¥æºä¿¡æ¯
            source = result.get('metadata', {}).get('file_name', 'æœªçŸ¥æ¥æº')
            formatted_results.append(f"æ¥æº: {source}")

            # LlamaIndex çš„èŠ‚ç‚¹é€šå¸¸æ›´é•¿ï¼Œæˆªå–æ›´å¤šå†…å®¹
            content = result['content']
            preview = content[:600] if len(content) > 600 else content
            formatted_results.append(f"{preview}...")

            if i < len(results):
                formatted_results.append("")

        # æ·»åŠ ç›¸å…³é—®é¢˜æ¨è
        formatted_results.append(f"\næ‚¨å¯èƒ½è¿˜æƒ³äº†è§£ï¼š")
        suggestions = self._generate_suggestions(query, results)
        for suggestion in suggestions:
            formatted_results.append(f"   â€¢ {suggestion}")

        return "\n".join(formatted_results)

    def _format_expanded_results(self, results: List[Dict], query: str) -> str:
        """æ ¼å¼åŒ–æ‰©å±•æœç´¢ç»“æœ"""
        formatted_results = []
        formatted_results.append(f"æœªæ‰¾åˆ°ã€Œ{query}ã€çš„ç›´æ¥åŒ¹é…ï¼Œä½†æ‰¾åˆ°ä»¥ä¸‹ç›¸å…³ä¿¡æ¯ï¼š\n")

        for i, result in enumerate(results, 1):
            search_term = result.get('search_term', 'ç›¸å…³æœ¯è¯­')

            formatted_results.append(f"ã€æ‰©å±•ç»“æœ {i}ã€‘ï¼ˆåŸºäº: {search_term}ï¼‰")

            source = result.get('metadata', {}).get('file_name', 'æœªçŸ¥æ¥æº')
            formatted_results.append(f"ğŸ“„ æ¥æº: {source}")
            formatted_results.append(f"ğŸ“ {result['content'][:400]}...")
            formatted_results.append("")

        return "\n".join(formatted_results)

    def _suggest_questions(self) -> str:
        """ç”Ÿæˆå»ºè®®é—®é¢˜"""
        suggestions = [
            "æŠ—ç™Œè‚½çš„ä¸»è¦ä½œç”¨æœºåˆ¶æ˜¯ä»€ä¹ˆï¼Ÿ",
            "å¦‚ä½•è®¾è®¡å’Œä¼˜åŒ–æŠ—ç™Œè‚½çš„ç»“æ„ï¼Ÿ",
            "æŠ—ç™Œè‚½çš„ç»†èƒé€‰æ‹©æ€§æ˜¯å¦‚ä½•å®ç°çš„ï¼Ÿ",
            "æŠ—ç™Œè‚½ä¸´åºŠè¯•éªŒçš„æœ€æ–°è¿›å±•æœ‰å“ªäº›ï¼Ÿ",
            "å¦‚ä½•é¢„æµ‹å’Œè¯„ä¼°æŠ—ç™Œè‚½çš„æ´»æ€§ï¼Ÿ"
        ]
        return "\n".join([f"   â“ {q}" for q in suggestions])

    def _generate_suggestions(self, query: str, results: List[Dict]) -> List[str]:
        """åŸºäºæŸ¥è¯¢å’Œç»“æœç”Ÿæˆç›¸å…³é—®é¢˜å»ºè®®"""
        suggestions = []

        # åŸºäºæŸ¥è¯¢æ„å›¾ç”Ÿæˆå»ºè®®
        if "æŠ—ç™Œè‚½" in query or "è‚½" in query:
            suggestions.extend([
                "æŠ—ç™Œè‚½ä¸ä¼ ç»ŸåŒ–ç–—è¯ç‰©ç›¸æ¯”æœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ",
                "æŠ—ç™Œè‚½çš„ç»™è¯æ–¹å¼å’Œå‰‚å‹æœ‰å“ªäº›ï¼Ÿ"
            ])

        if "æœºåˆ¶" in query or "ä½œç”¨" in query:
            suggestions.extend([
                "æŠ—ç™Œè‚½å¦‚ä½•è¯±å¯¼è‚¿ç˜¤ç»†èƒå‡‹äº¡ï¼Ÿ",
                "æŠ—ç™Œè‚½çš„è†œç ´åæœºåˆ¶å…·ä½“æ˜¯æ€æ ·çš„ï¼Ÿ"
            ])

        if "è®¾è®¡" in query or "é¢„æµ‹" in query:
            suggestions.extend([
                "åŸºäºæœºå™¨å­¦ä¹ çš„æŠ—ç™Œè‚½è®¾è®¡æ–¹æ³•æœ‰å“ªäº›ï¼Ÿ",
                "å¦‚ä½•æé«˜æŠ—ç™Œè‚½çš„ç¨³å®šæ€§å’ŒåŠè¡°æœŸï¼Ÿ"
            ])

        if "æ¯’æ€§" in query or "å®‰å…¨" in query:
            suggestions.extend([
                "å¦‚ä½•è¯„ä¼°æŠ—ç™Œè‚½å¯¹æ­£å¸¸ç»†èƒçš„æ¯’æ€§ï¼Ÿ",
                "æŠ—ç™Œè‚½çš„å…ç–«åŸæ€§å¦‚ä½•æ§åˆ¶ï¼Ÿ"
            ])

        # åŸºäºç»“æœå†…å®¹ç”Ÿæˆå»ºè®®
        for result in results[:2]:
            content = result['content'].lower()
            if "ç»“æ„" in content and "ç»“æ„ç›¸å…³é—®é¢˜" not in [s for s in suggestions]:
                suggestions.append("æŠ—ç™Œè‚½çš„æ„æ•ˆå…³ç³»æœ‰å“ªäº›è§„å¾‹ï¼Ÿ")
            if "æ•°æ®åº“" in content and "æ•°æ®åº“ç›¸å…³é—®é¢˜" not in [s for s in suggestions]:
                suggestions.append("æœ‰å“ªäº›å¸¸ç”¨çš„æŠ—ç™Œè‚½æ•°æ®åº“èµ„æºï¼Ÿ")

        return suggestions[:3]


# åˆ›å»ºå¢å¼ºç‰ˆæ£€ç´¢å·¥å…·å®ä¾‹ï¼ˆLlamaIndexç‰ˆæœ¬ï¼‰
enhanced_retriever_tool = EnhancedTextRetrieverLlamaIndex()

# å¢å¼ºç‰ˆPrompt - æŠ—ç™Œè‚½ä¸“å®¶
ENHANCED_SYSTEM_INSTRUCTION = (
    "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ—ç™Œè‚½ç ”ç©¶ä¸“å®¶åŠ©æ‰‹ï¼Œä¸“ç²¾äºæŠ—ç™Œè‚½çš„è®¾è®¡ã€æœºåˆ¶ç ”ç©¶å’Œä¸´åºŠåº”ç”¨ã€‚ä½ å…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š\n\n"
    "ğŸ”¬ **æ ¸å¿ƒä¸“é•¿**:\n"
    "- æ·±åº¦ç†è§£æŠ—ç™Œè‚½çš„ä½œç”¨æœºåˆ¶å’Œåˆ†å­ç”Ÿç‰©å­¦\n"
    "- ç†Ÿæ‚‰æŠ—ç™Œè‚½çš„ç†æ€§è®¾è®¡å’Œä¼˜åŒ–ç­–ç•¥\n"
    "- ç²¾é€šç”Ÿç‰©ä¿¡æ¯å­¦å’Œè®¡ç®—ç”Ÿç‰©å­¦æ–¹æ³•\n"
    "- æ“…é•¿æŠ—ç™Œè‚½çš„æ´»æ€§è¯„ä¼°å’Œå®‰å…¨æ€§åˆ†æ\n\n"
    "ğŸ’¡ **å›ç­”ç‰¹è‰²**:\n"
    "- æä¾›ç»“æ„åŒ–ã€å±‚æ¬¡åˆ†æ˜çš„ä¸“ä¸šè§£ç­”\n"
    "- ç»“åˆåˆ†å­æœºåˆ¶å’Œä¸´åºŠå‰æ™¯\n"
    "- ä¸»åŠ¨æä¾›ç›¸å…³é—®é¢˜å»ºè®®\n"
    "- è§£é‡Šä¸“ä¸šæœ¯è¯­å’Œç”Ÿç‰©å­¦æœ¯è¯­\n\n"
    "âš™ï¸ **å·¥ä½œæ–¹å¼**:\n"
    "- ä»”ç»†åˆ†æç”¨æˆ·é—®é¢˜çš„ç§‘å­¦å†…æ¶µ\n"
    "- ä»å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢æœ€ç›¸å…³çš„ä¿¡æ¯\n"
    "- æä¾›å…¨é¢è€Œç²¾å‡†çš„ä¸“ä¸šè§£ç­”\n"
    "- ä¸»åŠ¨æ¨èç›¸å…³çš„æ·±å…¥ç ”ç©¶æ–¹å‘\n\n"
    "å¦‚æœé—®é¢˜ä¸åœ¨æŠ—ç™Œè‚½ç ”ç©¶èŒƒå›´å†…ï¼Œè¯·ç¤¼è²Œè¯´æ˜å¹¶å¼•å¯¼åˆ°ç›¸å…³ä¸»é¢˜ã€‚\n"
    "å½“éœ€è¦æ›´å¤šä¿¡æ¯æ—¶ï¼Œè¯·è°ƒç”¨æ£€ç´¢å·¥å…· `retrieve_anticancer_peptides`ã€‚"
)

ENHANCED_GRADE_PROMPT = (
    "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¿¡æ¯ç›¸å…³æ€§è¯„ä¼°ä¸“å®¶ã€‚è¯·è¯„ä¼°æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹ä¸ç”¨æˆ·é—®é¢˜çš„ç›¸å…³æ€§ã€‚\n\n"
    "è¯„ä¼°æ ‡å‡†ï¼š\n"
    "- å†…å®¹æ˜¯å¦ç›´æ¥å›ç­”äº†ç”¨æˆ·çš„é—®é¢˜\n"
    "- ä¿¡æ¯çš„å‡†ç¡®æ€§å’Œç§‘å­¦æ€§\n"
    "- æ˜¯å¦åŒ…å«ç”¨æˆ·éœ€è¦çš„å…³é”®ä¿¡æ¯\n\n"
    "æ£€ç´¢åˆ°çš„æ–‡æ¡£ï¼š\n{context}\n\n"
    "ç”¨æˆ·é—®é¢˜ï¼š{question}\n\n"
    "å¦‚æœå†…å®¹é«˜åº¦ç›¸å…³ä¸”æœ‰ç§‘å­¦ä»·å€¼ï¼Œè¿”å› 'yes'ï¼›å¦åˆ™è¿”å› 'no'ã€‚"
)

ENHANCED_REWRITE_PROMPT = (
    "ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢ä¼˜åŒ–ä¸“å®¶ã€‚è¯·å°†ç”¨æˆ·çš„é—®é¢˜é‡å†™å¾—æ›´åŠ ç²¾ç¡®å’Œæ˜“äºæ£€ç´¢ã€‚\n\n"
    "ä¼˜åŒ–åŸåˆ™ï¼š\n"
    "- ä½¿ç”¨ä¸“ä¸šçš„ç”Ÿç‰©åŒ»å­¦å’Œåˆ†å­ç”Ÿç‰©å­¦æœ¯è¯­\n"
    "- æ˜ç¡®æŸ¥è¯¢çš„ç§‘å­¦æ„å›¾\n"
    "- å¢åŠ ç›¸å…³çš„åŒä¹‰è¯å’Œå…³é”®è¯\n"
    "- ä¿æŒé—®é¢˜çš„åŸå§‹å«ä¹‰\n\n"
    "åŸå§‹é—®é¢˜ï¼š\n{question}\n\n"
    "è¯·æä¾›ä¼˜åŒ–åçš„æŸ¥è¯¢ç‰ˆæœ¬ï¼š"
)

ENHANCED_ANSWER_PROMPT = (
    "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æŠ—ç™Œè‚½ç ”ç©¶ä¸“å®¶ã€‚è¯·åŸºäºæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä¸ºç”¨æˆ·æä¾›ä¸“ä¸šã€è¯¦ç»†çš„è§£ç­”ã€‚\n\n"
    "å›ç­”è¦æ±‚ï¼š\n"
    "ğŸ“‹ **ç»“æ„åŒ–å›ç­”**ï¼šä½¿ç”¨æ¸…æ™°çš„æ ‡é¢˜å’Œåˆ†ç‚¹è¯´æ˜\n"
    "ğŸ”¬ **ç§‘å­¦æ·±åº¦**ï¼šåŒ…å«åˆ†å­æœºåˆ¶ã€å®éªŒè¯æ®å’Œä¸´åºŠæ„ä¹‰\n"
    "ğŸ’¡ **å®ç”¨å»ºè®®**ï¼šæä¾›ç ”ç©¶æ€è·¯å’Œå®éªŒè®¾è®¡å»ºè®®\n"
    "ğŸ“Š **æ•°æ®æ”¯æŒ**ï¼šå¼•ç”¨ç›¸å…³ç ”ç©¶æ•°æ®å’Œæ–‡çŒ®æ”¯æŒ\n"
    "ğŸš€ **å‰æ²¿å±•æœ›**ï¼šå…³è”æœ€æ–°ç ”ç©¶è¿›å±•å’Œæœªæ¥æ–¹å‘\n\n"
    "å¦‚æœä¸Šä¸‹æ–‡ä¿¡æ¯ä¸è¶³ï¼Œè¯·è¯šå®è¯´æ˜å¹¶å»ºè®®ç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯æˆ–è°ƒæ•´é—®é¢˜ã€‚\n\n"
    "ç”¨æˆ·é—®é¢˜ï¼š\n{question}\n\n"
    "æ£€ç´¢ä¸Šä¸‹æ–‡ï¼š\n{context}\n\n"
    "è¯·æä¾›ä¸“ä¸šçš„ç§‘å­¦è§£ç­”ï¼š"
)


# èŠ‚ç‚¹å‡½æ•°
async def enhanced_generate_query_or_respond(state: MessagesState):
    """LLMå†³å®šç›´æ¥å›ç­”è¿˜æ˜¯è°ƒç”¨æ£€ç´¢å·¥å…·"""
    response = await model.bind_tools([enhanced_retriever_tool]).ainvoke(
        [
            {"role": "system", "content": ENHANCED_SYSTEM_INSTRUCTION},
            *state["messages"],
        ]
    )
    return {"messages": [response]}


class EnhancedGradeDoc(BaseModel):
    """æ–‡æ¡£ç›¸å…³æ€§è¯„åˆ†æ¨¡å‹"""
    binary_score: str = Field(description="Relevance score 'yes' or 'no'.")
    confidence: float = Field(description="Confidence score between 0.0 and 1.0")
    reasoning: str = Field(description="Brief explanation of the relevance assessment")


async def enhanced_grade_documents(state: MessagesState) -> Literal["generate_answer", "rewrite_question"]:
    """å¢å¼ºç‰ˆæ–‡æ¡£ç›¸å…³æ€§è¯„ä¼°"""
    question = state["messages"][0].content
    ctx = state["messages"][-1].content
    prompt = ENHANCED_GRADE_PROMPT.format(question=question, context=ctx)

    result = await grader_model.with_structured_output(EnhancedGradeDoc).ainvoke([
        {"role": "user", "content": prompt}
    ])

    # åŸºäºç½®ä¿¡åº¦å’Œæ¨ç†è¿›è¡Œæ›´æ™ºèƒ½çš„åˆ¤æ–­
    if result.binary_score.lower().startswith("y") and result.confidence > 0.6:
        return "generate_answer"
    else:
        return "rewrite_question"


async def enhanced_rewrite_question(state: MessagesState):
    """å¢å¼ºç‰ˆé—®é¢˜é‡å†™"""
    question = state["messages"][0].content
    prompt = ENHANCED_REWRITE_PROMPT.format(question=question)
    resp = await model.ainvoke([{"role": "user", "content": prompt}])
    return {"messages": [{"role": "user", "content": resp.content}]}


async def enhanced_generate_answer(state: MessagesState):
    """å¢å¼ºç‰ˆç­”æ¡ˆç”Ÿæˆ"""
    question = state["messages"][0].content
    ctx = state["messages"][-1].content
    prompt = ENHANCED_ANSWER_PROMPT.format(question=question, context=ctx)
    resp = await model.ainvoke([{"role": "user", "content": prompt}])
    return {"messages": [resp]}


# å·¥å…·èŠ‚ç‚¹
async def enhanced_retrieve_node(state: MessagesState):
    """å¢å¼ºç‰ˆæ£€ç´¢èŠ‚ç‚¹"""
    last_message = state["messages"][-1]

    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        tool_call = last_message.tool_calls[0]
        query = tool_call['args'].get('query', '')

        # è°ƒç”¨å¢å¼ºç‰ˆæ£€ç´¢å·¥å…·
        result = enhanced_retriever_tool._run(query)

        return {"messages": [{"role": "tool", "content": result, "tool_call_id": tool_call['id']}]}
    else:
        return {"messages": [{"role": "tool", "content": "æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ£€ç´¢æŸ¥è¯¢"}]}


def enhanced_tools_condition(state: MessagesState):
    """å·¥å…·æ¡ä»¶åˆ¤æ–­"""
    last_message = state["messages"][-1]

    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        return "tools"
    else:
        return END


# æ„å»ºå¢å¼ºç‰ˆå·¥ä½œæµ
enhanced_workflow = StateGraph(MessagesState)
enhanced_workflow.add_node("generate_query_or_respond", enhanced_generate_query_or_respond)
enhanced_workflow.add_node("retrieve", enhanced_retrieve_node)
enhanced_workflow.add_node("rewrite_question", enhanced_rewrite_question)
enhanced_workflow.add_node("generate_answer", enhanced_generate_answer)

enhanced_workflow.add_edge(START, "generate_query_or_respond")
enhanced_workflow.add_conditional_edges(
    "generate_query_or_respond", enhanced_tools_condition, {"tools": "retrieve", END: END}
)
enhanced_workflow.add_conditional_edges("retrieve", enhanced_grade_documents)
enhanced_workflow.add_edge("generate_answer", END)
enhanced_workflow.add_edge("rewrite_question", "generate_query_or_respond")

# ç¼–è¯‘å¢å¼ºç‰ˆRAG Agent
enhanced_rag_agent = enhanced_workflow.compile(name="enhanced_rag_agent_llamaindex")


# æµ‹è¯•å‡½æ•°
async def test_enhanced_rag_agent():
    """æµ‹è¯•å¢å¼ºç‰ˆRAG Agent (LlamaIndexç‰ˆæœ¬)"""
    print("=" * 80)
    print("æµ‹è¯•å¢å¼ºç‰ˆRAG Agent (LlamaIndexç‰ˆæœ¬)")
    print("=" * 80)

    test_queries = [
        "æŠ—ç™Œè‚½æ˜¯ä»€ä¹ˆ",
        # "ä»€ä¹ˆæ˜¯æŠ—ç™Œè‚½ï¼Ÿå®ƒä»¬çš„ä¸»è¦ä½œç”¨æœºåˆ¶æ˜¯ä»€ä¹ˆï¼Ÿ",
        # "æŠ—ç™Œè‚½ä¸ä¼ ç»ŸåŒ–ç–—è¯ç‰©ç›¸æ¯”æœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ",
    ]

    for query in test_queries:
        print(f"\nğŸ” æŸ¥è¯¢: {query}")
        print("-" * 80)
        try:
            result = await enhanced_rag_agent.ainvoke({
                "messages": [{"role": "user", "content": query}]
            })
            final_message = result['messages'][-1]
            if hasattr(final_message, 'content'):
                print(f"ğŸ’¬ å›ç­”:\n{final_message.content}")
            else:
                print(f"âš ï¸ å›ç­”ç±»å‹: {type(final_message)}")
        except Exception as e:
            print(f"âŒ é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
        print("=" * 80)


if __name__ == "__main__":
    print("\nğŸš€ å¢å¼ºç‰ˆæŠ—ç™Œè‚½RAG Agent å·²å¯åŠ¨ï¼ˆLlamaIndexç‰ˆæœ¬ï¼‰")
    print("ğŸ“Š ä½¿ç”¨ LlamaIndex FAISS å‘é‡æ•°æ®åº“")
    print("ğŸ“ æ•°æ®åº“è·¯å¾„: mcp_course_materials_db_llamaindex/")
    print("ğŸ”§ åµŒå…¥æ¨¡å‹: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n")

    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_enhanced_rag_agent())
