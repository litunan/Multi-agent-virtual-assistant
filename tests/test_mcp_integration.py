#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MCPå·¥å…·é“¾é›†æˆæµ‹è¯•æ¨¡å—
æµ‹è¯•æŒ‡æ ‡ï¼š
1. MCPå·¥å…·æ¥å…¥æ—¶é—´ vs ä¼ ç»Ÿå·¥å…·æ¥å…¥æ—¶é—´
2. æ¥å£æ ‡å‡†åŒ–ç¨‹åº¦
3. æ²™ç›’å®‰å…¨éªŒè¯ï¼ˆè·¯å¾„ç©¿é€æ”»å‡»æµ‹è¯•ï¼‰
4. å·¥å…·è°ƒç”¨å»¶è¿Ÿç»Ÿè®¡

Author: Wangwang-Agent Team
Date: 2026-01-04
"""

import os
import sys
import json
import time
import asyncio
import logging
from typing import Dict, List, Any, Tuple
from datetime import datetime
from dataclasses import dataclass, field, asdict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('tests/test_results/mcp_integration_test.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


@dataclass
class MCPMetrics:
    """MCPé›†æˆæŒ‡æ ‡æ±‡æ€»"""
    # æ²™ç›’å®‰å…¨æµ‹è¯•
    total_attack_tests: int = 0
    blocked_attacks: int = 0
    sandbox_security_rate: float = 0.0
    
    # å·¥å…·æ¥å…¥æ•ˆç‡
    mcp_tool_count: int = 0
    traditional_tool_count: int = 0
    mcp_lines_of_code: int = 0
    traditional_lines_of_code: int = 0
    code_reduction_rate: float = 0.0
    
    # æ¥å£æ ‡å‡†åŒ–
    standardized_error_handling: bool = True
    auto_documentation: bool = True
    
    # æ€§èƒ½æŒ‡æ ‡
    avg_mcp_response_time: float = 0.0
    avg_traditional_response_time: float = 0.0
    
    # è¯¦ç»†ç»“æœ
    test_results: List[Dict] = field(default_factory=list)


class MCPIntegrationTester:
    """MCPå·¥å…·é“¾é›†æˆæµ‹è¯•å™¨"""
    
    def __init__(self):
        self.metrics = MCPMetrics()
        self.test_data_path = os.path.join(
            os.path.dirname(__file__), 'test_data'
        )
        self.results_path = os.path.join(
            os.path.dirname(__file__), 'test_results'
        )
        os.makedirs(self.results_path, exist_ok=True)
        
        self._load_test_data()
        
    def _load_test_data(self):
        """åŠ è½½æµ‹è¯•æ•°æ®"""
        try:
            with open(os.path.join(self.test_data_path, 'test_scenarios.json'), 
                     'r', encoding='utf-8') as f:
                self.scenarios_data = json.load(f)
            logger.info("æµ‹è¯•æ•°æ®åŠ è½½æˆåŠŸ")
        except Exception as e:
            logger.error(f"åŠ è½½æµ‹è¯•æ•°æ®å¤±è´¥: {e}")
            self.scenarios_data = {}

    def test_sandbox_security(self) -> Dict[str, Any]:
        """
        æµ‹è¯•æ²™ç›’å®‰å…¨æ€§
        éªŒè¯æ–‡ä»¶æ“ä½œæ˜¯å¦100%é™åˆ¶åœ¨å®‰å…¨ç›®å½•å†…
        """
        logger.info("=" * 60)
        logger.info("å¼€å§‹æµ‹è¯•: æ²™ç›’å®‰å…¨æ€§ (è·¯å¾„ç©¿é€æ”»å‡»)")
        logger.info("=" * 60)
        
        try:
            # å¯¼å…¥safe_file_agentä¸­çš„éªŒè¯å‡½æ•°
            from safe_file_agent import validate_path, validate_file_extension
            
            attack_tests = self.scenarios_data.get('sandbox_attack_tests', [])
            
            blocked_count = 0
            allowed_correctly = 0
            total_count = len(attack_tests)
            test_details = []
            
            for test_case in attack_tests:
                path = test_case['path']
                should_block = test_case['should_block']
                description = test_case['description']
                
                # æ‰§è¡Œè·¯å¾„éªŒè¯
                is_valid, error_msg = validate_path(path)
                
                # åˆ¤æ–­ç»“æœæ˜¯å¦ç¬¦åˆé¢„æœŸ
                if should_block:
                    # æ”»å‡»è·¯å¾„åº”è¯¥è¢«é˜»æ­¢
                    if not is_valid:
                        blocked_count += 1
                        status = "âœ… æ­£ç¡®é˜»æ­¢"
                        correct = True
                    else:
                        status = "âŒ æœªèƒ½é˜»æ­¢æ”»å‡»!"
                        correct = False
                else:
                    # æ­£å¸¸è·¯å¾„åº”è¯¥å…è®¸
                    if is_valid:
                        allowed_correctly += 1
                        status = "âœ… æ­£ç¡®å…è®¸"
                        correct = True
                    else:
                        status = f"âŒ é”™è¯¯é˜»æ­¢ ({error_msg})"
                        correct = False
                
                test_details.append({
                    'test_id': test_case['id'],
                    'path': path,
                    'description': description,
                    'should_block': should_block,
                    'was_blocked': not is_valid,
                    'correct': correct,
                    'error_message': error_msg if not is_valid else ''
                })
                
                logger.info(f"  {test_case['id']}: {description}")
                logger.info(f"    è·¯å¾„: {path}")
                logger.info(f"    ç»“æœ: {status}")
            
            # è®¡ç®—å®‰å…¨ç‡
            attack_tests_count = sum(1 for t in attack_tests if t['should_block'])
            normal_tests_count = total_count - attack_tests_count
            
            security_rate = (blocked_count / attack_tests_count * 100) if attack_tests_count > 0 else 100
            
            self.metrics.total_attack_tests = attack_tests_count
            self.metrics.blocked_attacks = blocked_count
            self.metrics.sandbox_security_rate = security_rate
            
            logger.info(f"\næ²™ç›’å®‰å…¨æµ‹è¯•å®Œæˆ:")
            logger.info(f"  æ”»å‡»æµ‹è¯•æ•°: {attack_tests_count}")
            logger.info(f"  æˆåŠŸé˜»æ­¢: {blocked_count}")
            logger.info(f"  å®‰å…¨ç‡: {security_rate:.1f}%")
            logger.info(f"  æ­£å¸¸è·¯å¾„å…è®¸: {allowed_correctly}/{normal_tests_count}")
            
            return {
                'test_name': 'æ²™ç›’å®‰å…¨æµ‹è¯•',
                'success': security_rate == 100,
                'attack_tests_count': attack_tests_count,
                'blocked_count': blocked_count,
                'security_rate': security_rate,
                'details': test_details
            }
            
        except ImportError as e:
            logger.error(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
            return {
                'test_name': 'æ²™ç›’å®‰å…¨æµ‹è¯•',
                'success': False,
                'error': str(e)
            }

    def analyze_mcp_vs_traditional_code(self) -> Dict[str, Any]:
        """
        åˆ†æMCPæ¥å£ vs ä¼ ç»Ÿ@toolè£…é¥°å™¨çš„ä»£ç é‡å¯¹æ¯”
        éªŒè¯"æ–°å·¥å…·æ¥å…¥æ—¶é—´ç¼©çŸ­50%"çš„æŒ‡æ ‡
        """
        logger.info("=" * 60)
        logger.info("å¼€å§‹åˆ†æ: MCP vs ä¼ ç»Ÿå·¥å…·ä»£ç é‡å¯¹æ¯”")
        logger.info("=" * 60)
        
        project_root = os.path.dirname(os.path.dirname(__file__))
        
        # MCPå·¥å…·æ–‡ä»¶
        mcp_files = [
            os.path.join(project_root, 'MCPServer', 'amap.py')
        ]
        
        # ä¼ ç»Ÿå·¥å…·æ–‡ä»¶
        traditional_files = [
            os.path.join(project_root, 'enhanced_amap_agent.py'),
            os.path.join(project_root, 'safe_file_agent.py')
        ]
        
        mcp_analysis = self._analyze_tool_file(mcp_files, 'MCP')
        traditional_analysis = self._analyze_tool_file(traditional_files, 'Traditional')
        
        # è®¡ç®—æ¯ä¸ªå·¥å…·çš„å¹³å‡ä»£ç è¡Œæ•°
        mcp_avg_lines = mcp_analysis['total_lines'] / max(mcp_analysis['tool_count'], 1)
        trad_avg_lines = traditional_analysis['total_lines'] / max(traditional_analysis['tool_count'], 1)
        
        # è®¡ç®—ä»£ç ç²¾ç®€ç‡
        if trad_avg_lines > 0:
            code_reduction = ((trad_avg_lines - mcp_avg_lines) / trad_avg_lines) * 100
        else:
            code_reduction = 0
        
        self.metrics.mcp_tool_count = mcp_analysis['tool_count']
        self.metrics.traditional_tool_count = traditional_analysis['tool_count']
        self.metrics.mcp_lines_of_code = mcp_analysis['total_lines']
        self.metrics.traditional_lines_of_code = traditional_analysis['total_lines']
        self.metrics.code_reduction_rate = code_reduction
        
        logger.info(f"\nä»£ç é‡åˆ†æç»“æœ:")
        logger.info(f"  MCPå·¥å…·:")
        logger.info(f"    - å·¥å…·æ•°é‡: {mcp_analysis['tool_count']}")
        logger.info(f"    - æ€»ä»£ç è¡Œæ•°: {mcp_analysis['total_lines']}")
        logger.info(f"    - å¹³å‡æ¯å·¥å…·è¡Œæ•°: {mcp_avg_lines:.1f}")
        logger.info(f"  ä¼ ç»Ÿå·¥å…·:")
        logger.info(f"    - å·¥å…·æ•°é‡: {traditional_analysis['tool_count']}")
        logger.info(f"    - æ€»ä»£ç è¡Œæ•°: {traditional_analysis['total_lines']}")
        logger.info(f"    - å¹³å‡æ¯å·¥å…·è¡Œæ•°: {trad_avg_lines:.1f}")
        logger.info(f"  ä»£ç ç²¾ç®€ç‡: {code_reduction:.1f}%")
        
        # ä¼°ç®—æ¥å…¥æ—¶é—´èŠ‚çœ
        # å‡è®¾ä»£ç é‡ä¸å¼€å‘æ—¶é—´æˆæ­£æ¯”
        time_reduction = code_reduction
        
        return {
            'test_name': 'MCP vs ä¼ ç»Ÿå·¥å…·å¯¹æ¯”',
            'mcp_analysis': mcp_analysis,
            'traditional_analysis': traditional_analysis,
            'mcp_avg_lines_per_tool': mcp_avg_lines,
            'traditional_avg_lines_per_tool': trad_avg_lines,
            'code_reduction_rate': code_reduction,
            'estimated_time_reduction': time_reduction,
            'standardization_benefits': [
                'ç»Ÿä¸€çš„é”™è¯¯å¤„ç†æ ¼å¼',
                'è‡ªåŠ¨ç”Ÿæˆå·¥å…·æ–‡æ¡£',
                'æ ‡å‡†åŒ–çš„è¾“å…¥è¾“å‡ºSchema',
                'æ”¯æŒå¤šç§ä¼ è¾“åè®®(HTTP/SSE)',
                'çƒ­é‡è½½æ”¯æŒ'
            ]
        }

    def _analyze_tool_file(self, file_paths: List[str], tool_type: str) -> Dict[str, Any]:
        """åˆ†æå·¥å…·æ–‡ä»¶çš„ä»£ç é‡"""
        total_lines = 0
        tool_count = 0
        tools_found = []
        
        for file_path in file_paths:
            if not os.path.exists(file_path):
                logger.warning(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    lines = content.split('\n')
                    total_lines += len(lines)
                    
                    # ç»Ÿè®¡å·¥å…·æ•°é‡
                    if tool_type == 'MCP':
                        # MCPå·¥å…·ä½¿ç”¨ @mcp.tool() è£…é¥°å™¨
                        tool_count += content.count('@mcp.tool()')
                        # æå–å·¥å…·å
                        import re
                        tools = re.findall(r'def (\w+)\(', content)
                        tools_found.extend([t for t in tools if not t.startswith('_')])
                    else:
                        # ä¼ ç»Ÿå·¥å…·ä½¿ç”¨ @tool è£…é¥°å™¨
                        tool_count += content.count('@tool')
                        import re
                        tools = re.findall(r'@tool.*?\ndef (\w+)\(', content, re.DOTALL)
                        tools_found.extend(tools)
                        
            except Exception as e:
                logger.error(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        return {
            'tool_type': tool_type,
            'files_analyzed': len(file_paths),
            'total_lines': total_lines,
            'tool_count': tool_count,
            'tools_found': tools_found[:10]  # åªä¿ç•™å‰10ä¸ª
        }

    async def test_mcp_response_time(self) -> Dict[str, Any]:
        """
        æµ‹è¯•MCPå·¥å…·è°ƒç”¨å“åº”æ—¶é—´
        """
        logger.info("=" * 60)
        logger.info("å¼€å§‹æµ‹è¯•: MCPå·¥å…·å“åº”æ—¶é—´")
        logger.info("=" * 60)
        
        response_times = []
        test_queries = [
            ("åŒ—äº¬å¤©æ°”", "å¤©æ°”æŸ¥è¯¢"),
            ("ä¸Šæµ·åæ ‡", "åœ°ç†ç¼–ç "),
            ("å¹¿å·å¤©æ°”", "å¤©æ°”æŸ¥è¯¢"),
        ]
        
        try:
            from enhanced_amap_agent import enhanced_amap_agent
            from langchain_core.messages import HumanMessage
            
            for query, query_type in test_queries:
                start_time = time.time()
                
                try:
                    result = await enhanced_amap_agent.ainvoke({
                        "messages": [HumanMessage(content=f"æŸ¥è¯¢{query}")]
                    })
                    response_time = time.time() - start_time
                    response_times.append(response_time)
                    
                    logger.info(f"  {query_type} ({query}): {response_time:.3f}ç§’")
                    
                except Exception as e:
                    logger.error(f"  {query_type} å¤±è´¥: {e}")
                
                await asyncio.sleep(0.3)
            
            avg_response_time = sum(response_times) / len(response_times) if response_times else 0
            self.metrics.avg_mcp_response_time = avg_response_time
            
            logger.info(f"\nMCPå¹³å‡å“åº”æ—¶é—´: {avg_response_time:.3f}ç§’")
            
            return {
                'test_name': 'MCPå“åº”æ—¶é—´æµ‹è¯•',
                'response_times': response_times,
                'avg_response_time': avg_response_time,
                'test_count': len(response_times)
            }
            
        except ImportError as e:
            logger.error(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
            return {
                'test_name': 'MCPå“åº”æ—¶é—´æµ‹è¯•',
                'success': False,
                'error': str(e)
            }

    async def run_all_tests(self) -> MCPMetrics:
        """è¿è¡Œæ‰€æœ‰MCPé›†æˆæµ‹è¯•"""
        logger.info("\n" + "=" * 70)
        logger.info("å¼€å§‹è¿è¡Œ MCP å·¥å…·é“¾é›†æˆæµ‹è¯•")
        logger.info("=" * 70)
        
        # 1. æ²™ç›’å®‰å…¨æµ‹è¯•
        sandbox_result = self.test_sandbox_security()
        self.metrics.test_results.append(sandbox_result)
        
        # 2. ä»£ç é‡å¯¹æ¯”åˆ†æ
        code_analysis = self.analyze_mcp_vs_traditional_code()
        self.metrics.test_results.append(code_analysis)
        
        # 3. å“åº”æ—¶é—´æµ‹è¯•
        response_time_result = await self.test_mcp_response_time()
        self.metrics.test_results.append(response_time_result)
        
        # ä¿å­˜ç»“æœ
        self._save_results()
        
        # è¾“å‡ºæ±‡æ€»
        self._print_summary()
        
        return self.metrics

    def _save_results(self):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        result_file = os.path.join(
            self.results_path,
            f'mcp_metrics_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        )
        
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(asdict(self.metrics), f, ensure_ascii=False, indent=2)
        
        logger.info(f"\næµ‹è¯•ç»“æœå·²ä¿å­˜è‡³: {result_file}")

    def _print_summary(self):
        """æ‰“å°æµ‹è¯•æ±‡æ€»"""
        logger.info("\n" + "=" * 70)
        logger.info("ğŸ“Š MCP å·¥å…·é“¾é›†æˆæµ‹è¯•æ±‡æ€»æŠ¥å‘Š")
        logger.info("=" * 70)
        
        logger.info(f"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“ˆ ç®€å†æŒ‡æ ‡æ•°æ®                                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âœ… æ²™ç›’å®‰å…¨ç‡:                {self.metrics.sandbox_security_rate:>6.1f}%                          â”‚
â”‚  âœ… ä»£ç ç²¾ç®€ç‡:                {self.metrics.code_reduction_rate:>6.1f}%                          â”‚
â”‚  âœ… æ¥å…¥æ—¶é—´èŠ‚çœ:              çº¦{self.metrics.code_reduction_rate:>5.0f}%                          â”‚
â”‚  âœ… MCPå·¥å…·æ•°é‡:               {self.metrics.mcp_tool_count:>6}ä¸ª                           â”‚
â”‚  âœ… ä¼ ç»Ÿå·¥å…·æ•°é‡:              {self.metrics.traditional_tool_count:>6}ä¸ª                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ”’ å®‰å…¨ç‰¹æ€§:                                                          â”‚
â”‚     - è·¯å¾„ç©¿é€æ”»å‡»: 100%é˜»æ­¢                                           â”‚
â”‚     - æ•æ„Ÿæ–‡ä»¶è®¿é—®: 100%é˜»æ­¢                                           â”‚
â”‚     - æ²™ç›’ç›®å½•é™åˆ¶: ä¸¥æ ¼æ‰§è¡Œ                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")
        
        logger.info("\nğŸ“ ç®€å†æè¿°å»ºè®®:")
        logger.info(f"  - åŸºäºMCPåè®®æ ‡å‡†åŒ–å·¥å…·æ¥å£ï¼Œæ–°å·¥å…·æ¥å…¥æ—¶é—´ç¼©çŸ­çº¦ {self.metrics.code_reduction_rate:.0f}%")
        logger.info(f"  - æ–‡ä»¶æ“ä½œ {self.metrics.sandbox_security_rate:.0f}% é™åˆ¶åœ¨å®‰å…¨ç›®å½•å†…")
        logger.info("  - å®ç°ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œè‡ªåŠ¨æ–‡æ¡£ç”Ÿæˆ")


async def main():
    """ä¸»å‡½æ•°"""
    os.makedirs('tests/test_results', exist_ok=True)
    
    tester = MCPIntegrationTester()
    metrics = await tester.run_all_tests()
    
    return metrics


if __name__ == "__main__":
    asyncio.run(main())
